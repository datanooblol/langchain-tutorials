{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5970532-ddf3-463d-9e5a-601d526c71fb",
   "metadata": {},
   "source": [
    "[structured_output](https://python.langchain.com/v0.1/docs/integrations/chat/ollama_functions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5993ae-3642-4ecc-a0c4-b95bd548dcbf",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e1b05b-942a-436f-befb-bf14484ecb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package import embedding, llm, agent_llm, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88dcc949-f883-41b6-9f9d-593a9497a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(base_url=url, model=\"mistral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141a2b2-3113-4388-9ddc-02731600f0b6",
   "metadata": {},
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278572c9-f65c-4e8e-9d34-17da41ce1375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f5e739c-a90f-4a71-8927-193368906095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from typing import List, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99173a0-57f6-4c17-b041-6755450533b5",
   "metadata": {},
   "source": [
    "# Structured Output  \n",
    "\n",
    "Structuring your output into the desired format is one of many techniques you have to master.  \n",
    "The reasons is when you can format the output as the way you intend to, you open up more possibilites in creating the new way of work with LLM.  \n",
    "\n",
    "One of many examples of Sturctrued Output done right is:\n",
    "- use the output as instruction or logic in to another process, mostly done in Agent or LagnGraph scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3f136-d37b-4737-bbbd-b20bcb5e010c",
   "metadata": {},
   "source": [
    "## Structured within prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac7af74-d22c-4342-b8be-8073786bd873",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are an expert extraction algorithm who is keen of reading people emotion through the message.\n",
    "Your job is to classify the message wheter it is positive or negative.\n",
    "Only extract relavant information from the message.\n",
    "If you do not know the value of an attribute asked to extract, return null for the attribute's value.\n",
    "\n",
    "Here is the message: \\n\\n{message}<|eot_id|>\n",
    "\n",
    "<|start_header_id|>expert<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fffd399c-1201-4108-8b3c-a07c72353dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the given message, it can be classified as negative. Relevant information extraction:\n",
      "1. The speaker expresses strong dislike towards the recipient.\n",
      "2. The speaker states that they cannot endure the recipient's behavior anymore.\n",
      "3. The speaker threatens to cease communication with the recipient.\n"
     ]
    }
   ],
   "source": [
    "llm_chain = prompt | llm\n",
    "\n",
    "message = \"I can't stand you any more. The way you act is extremely unacceptable!! I won't talk to you again!!\"\n",
    "response = llm_chain.invoke({\"message\": message})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b4e057-ca0e-4e12-a32b-05fe4723a239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the given message, I would classify it as positive. The use of words like \"lovely,\" \"wanna pet her,\" and \"Muah!!,\" indicate a strong positive emotion towards the kitten. There is no relevant information to extract besides the emotional classification.\n"
     ]
    }
   ],
   "source": [
    "message = \"Awww this kitten is lovely. I wanna pet her so much. Muah!!\"\n",
    "response = llm_chain.invoke({\"message\": message})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "647bb88d-e9e3-4fca-a4bc-fbf53827e440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Based on the given message, I would classify it as positive. The message conveys that the speaker finds the pug to be cute and enjoys the pug's behavior of coming up to them and sleeping on their lap. No specific information is asked to be extracted from this message, so no value will be returned for any attribute.\n"
     ]
    }
   ],
   "source": [
    "message = \"This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!\"\n",
    "response = llm_chain.invoke({\"message\": message})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6912fbc-24d7-4be1-a154-fa7f262ffc36",
   "metadata": {},
   "source": [
    "## Caution\n",
    "llm.with_structured_output(schema=SentimentExtractor): llama3 and minstral can't use this method due to non-implementation issue  \n",
    "Hence use this below workaround techniques with parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c060db5-0415-422a-849c-113ec7195885",
   "metadata": {},
   "source": [
    "## Structured in Pydantic way and later add to prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c08e366-8756-483f-acf5-f72f600f962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentExtractor(BaseModel):\n",
    "    \"\"\"Sentiment of a message.\"\"\"\n",
    "    sentiment:Optional[str] = Field(default=None, description=\"The sentiment of the message\")\n",
    "    emotion:Optional[str] = Field(default=None, description=\"The emotion of the message\")\n",
    "    tone:Optional[str] = Field(default=None, description=\"The tone of the message\")\n",
    "    intent:Optional[str] = Field(default=None, description=\"The intent of the message\")\n",
    "    action:Optional[str] = Field(default=None, description=\"The action of the message\")\n",
    "    summary:Optional[str] = Field(default=None, description=\"The summary of the message\")\n",
    "    message:Optional[str] = Field(default=None, description=\"The input message\")\n",
    "    entity:Optional[str] = Field(default=None, description=\"The entity of the message\")\n",
    "\n",
    "# class SentimentExtractor(BaseModel):\n",
    "#     \"\"\"Sentiment of a message.\"\"\"\n",
    "#     sentiment:str = Field(description=\"The sentiment of the message\")\n",
    "#     emotion:str = Field(description=\"The emotion of the message\")\n",
    "#     tone:str = Field(description=\"The tone of the message\")\n",
    "#     intent:str = Field(description=\"The intent of the message\")\n",
    "#     action:str = Field(description=\"The action of the message\")\n",
    "#     summary:str = Field(description=\"The summary of the message\")\n",
    "#     message:str = Field(description=\"The input message\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=SentimentExtractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97c1d56-01f4-4663-969c-cd6fb73264c6",
   "metadata": {},
   "source": [
    "## Normal prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7eff6947-bbf3-46ea-a030-62ad27536e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'negative',\n",
       " 'emotion': 'anger',\n",
       " 'tone': 'aggressive',\n",
       " 'intent': 'expressing disappointment and anger towards someone',\n",
       " 'action': 'ending a relationship or communication',\n",
       " 'summary': 'The person expresses their frustration and intention to end contact with another person.',\n",
       " 'message': \"I can't stand you any more. The way you act is extremely unacceptable!! I swear I won't talk to you again!\",\n",
       " 'entity': ''}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\"Answer the message.\\n{format_instructions}\n",
    "Remember do not add preamble or explanation.\n",
    "\n",
    "Here is a message: \\n\\n{message}<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"message\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "message = \"I can't stand you any more. The way you act is extremely unacceptable!! I swear I won't talk to you again!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3accff14-f733-408f-a57c-02b76f23aef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'This pug is crazy, haha. He always comes up to me and sleeps on my lap. What a cutie pie!',\n",
       " 'sentiment': 'positive',\n",
       " 'emotion': 'happy',\n",
       " 'tone': 'playful',\n",
       " 'intent': 'expressing affection for a pet',\n",
       " 'action': 'interacting with the pet',\n",
       " 'summary': 'The sender is describing their interaction with a pug and expressing positive emotions towards it.',\n",
       " 'entity': 'pug'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a23ed93b-f1ee-4ae6-8fb9-3fea4e7752bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I'm sorry to hear that the relationship between you and the other person has reached a point where they feel they can no longer communicate with you. It's important to respect their decision and give them space if that's what they need. If there is any way to address the issues that led to this situation, it may be helpful to do so in a calm and respectful manner, but only if both parties are open to it. Otherwise, it might be best to focus on your own well-being and move forward.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\"Answer the message.\n",
    "\n",
    "Here is a message: \\n\\n{message}<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"message\"],\n",
    "    # partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "message = \"I can't stand you any more. The way you act is extremely unacceptable!! I swear I won't talk to you again!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1a86afe-3a59-426b-b5ea-9e61ed7afe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " It sounds like you're sharing an affectionate moment with your pug. Pugs are known for their friendly and lovable personalities, so it's not surprising that this one enjoys being close to you. Enjoy the bonding experience with your furry friend!\n"
     ]
    }
   ],
   "source": [
    "message = \"This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b498e5fe-d60f-4361-a315-a92446af97aa",
   "metadata": {},
   "source": [
    "## Refined prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "227070c9-0087-413d-8aab-17eff926445d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'negative',\n",
       " 'emotion': 'anger',\n",
       " 'tone': 'aggressive',\n",
       " 'intent': 'breakup',\n",
       " 'action': 'ending a relationship',\n",
       " 'summary': 'The message expresses anger and intent to end a relationship.',\n",
       " 'message': \"I can't stand you any more. The way you act is extremely unacceptable!! I swear I won't talk to you again!\"}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are an expert extraction algorithm who is keen of reading people through the message.\n",
    "Only extract relavant information from the message.\n",
    "If you do not know the value of an attribute asked to extract, return null for the attribute's value.\n",
    "{format_instructions}\n",
    "Remember do not add preamble or explanation.\n",
    "Provide the answer in JSON format.\n",
    "Here is a message: \\n\\n{message}<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"message\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "message = \"I can't stand you any more. The way you act is extremely unacceptable!! I swear I won't talk to you again!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "911e9396-af6e-41e9-8faf-e3f0d3e7ba93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'negative',\n",
       " 'emotion': 'anger',\n",
       " 'tone': 'aggressive',\n",
       " 'intent': 'conflict',\n",
       " 'action': 'refusal to communicate',\n",
       " 'summary': \"The sender's brother has expressed his displeasure with the recipient and has sworn off communication.\",\n",
       " 'message': \"My brother can't stand you any more. The way you act is extremely unacceptable!! He sweared he won't talk to you again!\"}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"My brother can't stand you any more. The way you act is extremely unacceptable!! He sweared he won't talk to you again!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f4358d9e-a904-4bc8-842e-2252d5aed92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'This pug is crazy, haha. He always comes up to me and sleeps on my lap. What a cutie pie!',\n",
       " 'sentiment': 'positive',\n",
       " 'emotion': ['happy'],\n",
       " 'tone': ['playful'],\n",
       " 'intent': 'Expressing affection for the pug',\n",
       " 'summary': 'The sender is expressing positive emotions and describes the playful behavior of a pug that sleeps on their lap.',\n",
       " 'entity': 'pug'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d345011e-f2c1-4975-8d18-2a35f8a34727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'Oh Jeez! This pizza is out of the world. Where did you get it? I wanna buy some more!',\n",
       " 'sentiment': 'positive',\n",
       " 'emotion': 'excited',\n",
       " 'tone': 'friendly',\n",
       " 'intent': 'Purchase request',\n",
       " 'summary': 'The user expresses excitement about a pizza they have tried and requests to purchase more. They did not specify the location where they got it from.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"Oh Jeez! This pizza is out of the world. Where did you get it? I wanna buy some more!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f5c2adf3-3e7c-4596-baf5-3cb8204855cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "\"sentiment\": \"negative\",\n",
      "\"relation_status\": \"unwanted\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are an expert extraction algorithm who is keen of reading people through the message.\n",
    "Only extract relavant information from the message.\n",
    "If you do not know the value of an attribute asked to extract, return null for the attribute's value.\n",
    "Remember do not add preamble or explanation.\n",
    "Provide the answer in JSON format.\n",
    "\n",
    "Here is a message: \\n\\n{message}<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"message\"],\n",
    "    # partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "message = \"I can't stand you any more. The way you act is extremely unacceptable!! I don't wanna talk to you any more\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "# json.loads(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e5ef961-7c24-4bd9-8454-17e07fee7336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'animal_type': 'pug', 'behavior': ['comes up to person', 'sleeps on lap']}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65026c68-9883-46fd-ad5d-634564530051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {\n",
      "\"animal_type\": \"pug\",\n",
      "\"behavior\": [\"comes up to person\", \"sleeps on lap\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "message = \"This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "# json.loads(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa11f12-9c58-49b4-af47-c00971f13ea4",
   "metadata": {},
   "source": [
    "# Play Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf033ef7-dde8-480f-842e-88dd33980653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
