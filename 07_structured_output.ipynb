{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5970532-ddf3-463d-9e5a-601d526c71fb",
   "metadata": {},
   "source": [
    "[structured_output](https://python.langchain.com/v0.1/docs/integrations/chat/ollama_functions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5993ae-3642-4ecc-a0c4-b95bd548dcbf",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90e1b05b-942a-436f-befb-bf14484ecb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package import embedding, llm, agent_llm, url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88dcc949-f883-41b6-9f9d-593a9497a7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(base_url=url, model=\"mistral\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141a2b2-3113-4388-9ddc-02731600f0b6",
   "metadata": {},
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "278572c9-f65c-4e8e-9d34-17da41ce1375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f5e739c-a90f-4a71-8927-193368906095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99173a0-57f6-4c17-b041-6755450533b5",
   "metadata": {},
   "source": [
    "# Structured Output  \n",
    "\n",
    "Structuring your output into the desired format is one of many techniques you have to master.  \n",
    "The reasons is when you can format the output as the way you intend to, you open up more possibilites in creating the new way of work with LLM.  \n",
    "\n",
    "One of many examples of Sturctrued Output done right is:\n",
    "- use the output as instruction or logic in to another process, mostly done in Agent or LagnGraph scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af3f136-d37b-4737-bbbd-b20bcb5e010c",
   "metadata": {},
   "source": [
    "## Structured within prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac7af74-d22c-4342-b8be-8073786bd873",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are an expert extraction algorithm who is keen of reading people emotion through the message.\n",
    "Your job is to classify the message wheter it is positive or negative.\n",
    "Only extract relavant information from the message.\n",
    "If you do not know the value of an attribute asked to extract, return null for the attribute's value.\n",
    "\n",
    "Here is the message: \\n\\n{message}<|eot_id|>\n",
    "\n",
    "<|start_header_id|>expert<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fffd399c-1201-4108-8b3c-a07c72353dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the message, I would classify it as **Negative**.\n",
      "\n",
      "The relevant information extracted from the message includes:\n",
      "\n",
      "* Sentiment: Negative\n",
      "* Emotion: Anger/Frustration\n",
      "* Tone: Disgust/Disapproval\n",
      "* Intent: To express strong disapproval and unwillingness to communicate further.\n"
     ]
    }
   ],
   "source": [
    "llm_chain = prompt | llm\n",
    "\n",
    "message = \"I can't stand you any more. The way you act is extremely unacceptable!! I won't talk to you again!!\"\n",
    "response = llm_chain.invoke({\"message\": message})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03b4e057-ca0e-4e12-a32b-05fe4723a239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I've analyzed the message and extracted the following information:\n",
      "\n",
      "* Sentiment: Positive\n",
      "* Emotion: Joy, Affection (due to the use of words like \"lovely\", \"wanna pet\", and \"Muah!!\")\n",
      "* Tone: Playful, Excited\n",
      "* Keywords: Kitten, Pet, Lovely\n",
      "\n",
      "Overall, the message has a very positive tone and conveys a sense of joy and affection towards the kitten.\n"
     ]
    }
   ],
   "source": [
    "message = \"Awww this kitten is lovely. I wanna pet her so much. Muah!!\"\n",
    "response = llm_chain.invoke({\"message\": message})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "647bb88d-e9e3-4fca-a4bc-fbf53827e440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A delightful message!\n",
      "\n",
      "After analyzing the text, I can extract the following information:\n",
      "\n",
      "* Sentiment: Positive\n",
      "* Emotion: Joy/Friendliness (indicated by \"haha\" and \"cutie pie\")\n",
      "* Tone: Playful/Lighthearted\n",
      "* Entity: Pug (the subject of the message)\n",
      "* Action: The pug comes up to the speaker and sleeps on their lap\n",
      "\n",
      "Overall, this message has a very positive tone and conveys a sense of joy and affection towards the pug.\n"
     ]
    }
   ],
   "source": [
    "message = \"This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!\"\n",
    "response = llm_chain.invoke({\"message\": message})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6912fbc-24d7-4be1-a154-fa7f262ffc36",
   "metadata": {},
   "source": [
    "## Caution\n",
    "llm.with_structured_output(schema=SentimentExtractor): llama3 and minstral can't use this method due to non-implementation issue  \n",
    "Hence use this below workaround techniques with parser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c060db5-0415-422a-849c-113ec7195885",
   "metadata": {},
   "source": [
    "## Structured in Pydantic way and later add to prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9c08e366-8756-483f-acf5-f72f600f962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentExtractor(BaseModel):\n",
    "    \"\"\"Sentiment of a message.\"\"\"\n",
    "    sentiment:Optional[str] = Field(default=None, description=\"The sentiment of the message\")\n",
    "    emotion:Optional[str] = Field(default=None, description=\"The emotion of the message\")\n",
    "    tone:Optional[str] = Field(default=None, description=\"The tone of the message\")\n",
    "    intent:Optional[str] = Field(default=None, description=\"The intent of the message\")\n",
    "    action:Optional[str] = Field(default=None, description=\"The action of the message\")\n",
    "    summary:Optional[str] = Field(default=None, description=\"The summary of the message\")\n",
    "    message:Optional[str] = Field(default=None, description=\"The input message\")\n",
    "\n",
    "# class SentimentExtractor(BaseModel):\n",
    "#     \"\"\"Sentiment of a message.\"\"\"\n",
    "#     sentiment:str = Field(description=\"The sentiment of the message\")\n",
    "#     emotion:str = Field(description=\"The emotion of the message\")\n",
    "#     tone:str = Field(description=\"The tone of the message\")\n",
    "#     intent:str = Field(description=\"The intent of the message\")\n",
    "#     action:str = Field(description=\"The action of the message\")\n",
    "#     summary:str = Field(description=\"The summary of the message\")\n",
    "#     message:str = Field(description=\"The input message\")\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=SentimentExtractor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97c1d56-01f4-4663-969c-cd6fb73264c6",
   "metadata": {},
   "source": [
    "## Normal prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7eff6947-bbf3-46ea-a030-62ad27536e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'Negative',\n",
       " 'emotion': 'Anger',\n",
       " 'tone': 'Confrontational',\n",
       " 'intent': 'To express disapproval',\n",
       " 'action': 'To avoid further interaction',\n",
       " 'summary': 'The speaker is expressing strong dislike and frustration towards the person they are talking to.',\n",
       " 'message': \"I can't stand you any more. The way you act is extremely unacceptable!! I swear I won't talk to you again!\"}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\"Answer the message.\\n{format_instructions}\n",
    "\n",
    "Here is a message: \\n\\n{message}<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"message\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "message = \"I can't stand you any more. The way you act is extremely unacceptable!! I swear I won't talk to you again!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3accff14-f733-408f-a57c-02b76f23aef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'POSITIVE',\n",
       " 'emotion': 'JOYFUL',\n",
       " 'tone': 'PLAYFUL',\n",
       " 'intent': 'AFFECTIONATE',\n",
       " 'action': 'EXPRESSION_OF_LOVE',\n",
       " 'summary': 'A PERSON IS DESCRIBING THEIR EXPERIENCE WITH A PUG THAT SLEEP ON THEIR LAP',\n",
       " 'message': 'This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a23ed93b-f1ee-4ae6-8fb9-3fea4e7752bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm so sorry to hear that you're feeling upset and frustrated with me. It sounds like we've reached an impasse, and I want to acknowledge the hurt and anger you're experiencing.\n",
      "\n",
      "Before we go our separate ways, can I ask what specifically has been bothering you about my behavior? Is there something specific that's causing you distress or discomfort?\n",
      "\n",
      "I'm here to listen and understand your perspective. If there's anything I can do to make amends or improve our communication, please let me know.\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\"Answer the message.\n",
    "\n",
    "Here is a message: \\n\\n{message}<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"message\"],\n",
    "    # partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "message = \"I can't stand you any more. The way you act is extremely unacceptable!! I swear I won't talk to you again!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d1a86afe-3a59-426b-b5ea-9e61ed7afe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's so sweet! It sounds like you have a special bond with your furry friend. Pugs are known for their affectionate nature, and it's great that he feels comfortable enough to snuggle up with you. Enjoy those cuddles and cherish the moments with your little buddy!\n"
     ]
    }
   ],
   "source": [
    "message = \"This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b498e5fe-d60f-4361-a315-a92446af97aa",
   "metadata": {},
   "source": [
    "## Refined prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "227070c9-0087-413d-8aab-17eff926445d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'Negative',\n",
       " 'emotion': 'Anger',\n",
       " 'tone': 'Confrontational',\n",
       " 'intent': 'To express frustration and disapproval',\n",
       " 'action': 'To avoid further interaction',\n",
       " 'summary': 'The speaker is expressing strong negative emotions towards the person they are talking to, stating that their behavior is unacceptable and they will not interact with them again.',\n",
       " 'message': \"I can't stand you any more. The way you act is extremely unacceptable!! I swear I won't talk to you again!\"}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are an expert extraction algorithm who is keen of reading people through the message.\n",
    "Only extract relavant information from the message.\n",
    "If you do not know the value of an attribute asked to extract, return null for the attribute's value.\n",
    "{format_instructions}\n",
    "Here is a message: \\n\\n{message}<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"message\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "message = \"I can't stand you any more. The way you act is extremely unacceptable!! I swear I won't talk to you again!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f4358d9e-a904-4bc8-842e-2252d5aed92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'POSITIVE',\n",
       " 'emotion': 'JOYFUL',\n",
       " 'tone': 'PLAYFUL',\n",
       " 'intent': 'AFFECTIONATE',\n",
       " 'action': 'EXPRESSION_OF_AFFECTION',\n",
       " 'summary': 'The speaker is expressing their affection for a pug and describing its playful behavior.',\n",
       " 'message': 'This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!'}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d345011e-f2c1-4975-8d18-2a35f8a34727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': 'POSITIVE',\n",
       " 'emotion': 'EXCITEMENT',\n",
       " 'tone': 'ENTHUSIASTIC',\n",
       " 'intent': 'INQUIRY',\n",
       " 'action': 'PURCHASE',\n",
       " 'summary': 'The speaker is excited about the pizza and wants to buy more.',\n",
       " 'message': 'Oh Jeez! This pizza is out of the world. Where did you get it? I wanna buy some more!'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = \"Oh Jeez! This pizza is out of the world. Where did you get it? I wanna buy some more!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "json.loads(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f5c2adf3-3e7c-4596-baf5-3cb8204855cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After analyzing the message, I extracted the following relevant information:\n",
      "\n",
      "* Sentiment: Negative\n",
      "* Reason for negative sentiment: Unacceptable behavior\n",
      "* Requested action: Don't want to talk to the person anymore\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "You are an expert extraction algorithm who is keen of reading people through the message.\n",
    "Only extract relavant information from the message.\n",
    "If you do not know the value of an attribute asked to extract, return null for the attribute's value.\n",
    "\n",
    "Here is a message: \\n\\n{message}<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"message\"],\n",
    "    # partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "message = \"I can't stand you any more. The way you act is extremely unacceptable!! I don't wanna talk to you any more\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "# json.loads(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "65026c68-9883-46fd-ad5d-634564530051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After analyzing the message, I extracted the following relevant information:\n",
      "\n",
      "* Breed of dog: Pug\n",
      "* Behavior: Comes up to the speaker and sleeps on their lap\n",
      "* Adjective used to describe the dog: Crazy, Cutie Pie\n"
     ]
    }
   ],
   "source": [
    "message = \"This pug is crazy, haha. He always comes up to me and sleep on my lap. What a cutie pie!\"\n",
    "response = llm_chain.invoke({\"message\":message})\n",
    "# json.loads(response)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa11f12-9c58-49b4-af47-c00971f13ea4",
   "metadata": {},
   "source": [
    "# Play Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf033ef7-dde8-480f-842e-88dd33980653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
