{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5993ae-3642-4ecc-a0c4-b95bd548dcbf",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e1b05b-942a-436f-befb-bf14484ecb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package import embedding, llm, agent_llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4141a2b2-3113-4388-9ddc-02731600f0b6",
   "metadata": {},
   "source": [
    "# Import Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f0a4f34-d9a4-41bb-be8b-2bcf3da4f067",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5e739c-a90f-4a71-8927-193368906095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c8b4c58-d99b-4816-88b0-daf33efe2dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fb49d14-17f8-412a-8ea6-1f1b2bac7117",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "448cffac-68db-4237-8c51-c0bf1bb0d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d9f795-e724-4bae-b580-4267449f8d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad50fb80-18ce-4149-952d-2514b3b01200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from package.utils import format_docs, prompt_2_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaa6c4e-e3a1-43c8-acc9-f21440f8bd5e",
   "metadata": {},
   "source": [
    "# UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f4678b-8633-4355-a06d-fadbf74696fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26ba18c-2442-48b0-9091-c9ad7fb87bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_2_str(prompt):\n",
    "    return prompt.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea2987-414b-4837-929f-f9c2c9d582de",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "047503bd-92bf-4c45-a3aa-032709a5233e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "# from langchain_openai import OpenAI\n",
    "\n",
    "# model = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0.0)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "prompt_and_model = prompt | llm\n",
    "output = prompt_and_model.invoke({\"query\": \"Tell me a joke.\"})\n",
    "response = parser.invoke(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b99cbd55-6780-44fb-a0e7-68d525b5d720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "696c36ea-5501-4788-8505-1ce44f92e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup=\"Why don't scientists trust atoms?\" punchline='Because they make up everything!'\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b92c7894-4ea2-4cad-8409-c15341259890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't scientists trust atoms?\",\n",
       " 'punchline': 'Because they make up everything!'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e5045f2-2e5c-4a67-bb27-bf50d3e7622e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bff2c8-5a2c-4349-90ea-2fbb614bab50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
